----------------------
|  scRNA-seq Yu Lab  |
----------------------

Christian Chua
Bioninformatics 624
Fall 2020

----------------------
| Table of Contents  |
----------------------

Date        Description
10/07/2020  Temporary Data Location; Data Exploration
10/08/2020  Data Exploration II
10/13/2020  Info on 10x Genomics, CellRanger, and Seurat
10/16/2020  Run Cellranger Counts
10/25/2020  Run FASTQC on fastq files
10/26/2020  Run v4 trimmed raw and filtered counts through seurat on talapas

----------------------
|     10/07/2020     |
----------------------

Objective: Document Data Information; Data Exploration
Description: Figure out why there are less index reads than the files. 10x Genomics

I. GitHub
    A. Locations
        GitHubLink: https://github.com/2020-bgmp/group-projects-yu-lab-project
        Local computer: /home/cchua/bioinformatics/group-projects-yu-lab-project
        Talapas (temporary): /projects/bgmp/mchang3/temp_proj_dir/data
        Talapas (permanent): /projects/bgmp/shared/groups/2020/neuron_nerds
        Google Drive: https://drive.google.com/drive/folders/1gaivw0KDvIC3jG6LDb2otxM6PMkNQBCS
            - meeting notes
            - group assignments
    B. Clone repo
        NOTE: created readme.MD file to clone
        git clone https://github.com/2020-bgmp/group-projects-yu-lab-project.git
        cd group-projects-yu-lab-project/
        git remote rename origin upstream
        git remote add origin https://github.com/2020-bgmp/group-projects-yu-lab-project.git
        git remote -v
        git pull origin master
        git push -u origin master
    C. Configure Git
        git config --global user.email "chrisanthony92@ymail.com"
        git config --global user.name "Chris-Anthony"
    D. Commit Lab Notebook
        git add scRNAseq_Yu_lab-notebook.txt
        git status
        git commit -m "Chris' Lab Notebook"
        git push
        git pull
II. Data Exploration
    A. interactive session
        srun --account=bgmp --partition=bgmp --nodes=1 --ntasks-per-node=1 \
        --time=2:00:00 --cpus-per-task=1 --pty bash

        squeue -u cchua
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
          13184935      bgmp     bash    cchua  R       0:07      1 n225
    B. List files
         ls -1
            P10.index.fq.gz
            P10.md5
            P10.read1.fastq.gz
            P10.read2.fastq.gz
    C. Check data integrity
        cat P10.md5
            279aac0db745cee15a50f780f1db2b60  P10.read1.fastq.gz
            ff4717b14975c9d60d910df461b46f88  P10.read2.fastq.gz
            622b7c61c38b109298458caa37d5cab4  P10.index.fq.gz
        md5sum P10.index.fq.gz
            622b7c61c38b109298458caa37d5cab4  P10.index.fq.gz
        md5sum P10.read1.fastq.gz
            279aac0db745cee15a50f780f1db2b60  P10.read1.fastq.gz
        md5sum P10.read2.fastq.gz
            ff4717b14975c9d60d910df461b46f88  P10.read2.fastq.gz
    D. Head each file
        zcat P10.index.fq.gz | head
            @D00575:498:HK7KCBCX2:1:1102:1429:1888 1:N:0:TCAGCCGT
            TCAGCCGT
            +
            DDDDDIII
            @D00575:498:HK7KCBCX2:1:1102:1392:1911 1:N:0:TCAGCCGT
            TCAGCCGT
            +
            DDDDDIII
            @D00575:498:HK7KCBCX2:1:1102:1395:1983 1:N:0:TCAGCCGT
            TCAGCCGT
        zcat P10.read1.fastq.gz | head
            @D00575:548:HTLKKBCX2:1:1104:1179:1841 1:N:0:TCAGCCGT
            NATATGGAGTGACATAACCCACGGTTT
            +
            #<DDDIIIIIIIIIIIIIIIIIIIIIH
            @D00575:548:HTLKKBCX2:1:1104:1137:1877 1:N:0:TCAGCCGT
            NAGGTTCGTTCGGGCTAGGGGGTTGAT
            +
            #<DDDHIIHIIIIIIIIIHHDIEHHIH
            @D00575:548:HTLKKBCX2:1:1104:1104:1901 1:N:0:TCAGCCGT
            ACGCAGCAGTACACCTCTATCTGTCGT
        zcat P10.read2.fastq.gz | head
            @D00575:548:HTLKKBCX2:1:1104:1179:1841 2:N:0:TCAGCCGT
            CTCGCCCCTACCATTGGGACAGGAATGTCATGTCACCCCATCGTCCTGTGTCTCCCACCATCGCTATGCAAAGTGGTTCTTGTTGTACATAAGATTTAA
            +
            DDDDDIIIIIIHHIIIGIIHHHC@HEHHHIHHIIIIIIHHIIIIIIHIIGHHHIIIHIIIIIIIIHHHHHEHHHIIIHEHHHFH@GFHIHHIHHIHFHH
            @D00575:548:HTLKKBCX2:1:1104:1137:1877 2:N:0:TCAGCCGT
            GGCCAAACAGGAAAAGAAGAAGAAGAAGACAGGCCGGGCCAAGAGGCGAATGCAGTACAACCGGCGCTTTGTCAATGTTGTGCCCACCTTTGGGAAGAA
            +
            DDDDDIHGIIIGFEHH@FH@CECEE1<GCH@@CEHHIHHIIHHFHGHIIHIIIHIHHIIIIIGHHHIIIIIIHIIIEH@GHIIHIGHIHGHHIHIIIEE
            @D00575:548:HTLKKBCX2:1:1104:1104:1901 2:N:0:TCAGCCGT
            GGTCGCCAAAGTGACAGCCGGCGCCGCGTCCAAGCTCTCCAAGATACGAGTCGTTCGCAAGTCTATCGCCCGAGTCCTCACTGTTATGAACCAGACTCA
        conclusions:
        - paired reads, same locations in the header lines
        - the lengths of the two reads are different - 10x Genomic Specific?
        - where is the bitwise flag?
        - header lines contain the barcodes information
        - there is only 1 index file
    E. Tail each file 
        zcat P10.index.fq.gz | tail
            +
            @0<D@FHH
            @D00575:498:HK7KCBCX2:2:2216:20762:101228 1:N:0:ATCTTTAG
            ATCTTTAG
            +
            D@BDDIII
            @D00575:498:HK7KCBCX2:2:2216:21093:101121 1:N:0:ATCTTTAG
            ATCTTTAG
            +
            DD0DDC1<
         zcat P10.read1.fastq.gz | tail
            +
            D00D@<1C@FHHFFHHHI/1F1FH1<D
            @D00575:548:HTLKKBCX2:2:2216:21294:101002 1:N:0:ATCTTTAG
            GTTCTCGCAGCCTATATTGCCACACGT
            +
            DDDDDIHHIHGGHIIIHIHHHGHIIIH
            @D00575:548:HTLKKBCX2:2:2216:21271:101030 1:N:0:ATCTTTAG
            CGTCTACTCTCTTATGCGACTTTTGTT
            +
            D@BD?<FHHIHIEF?11EC//EGC@HH
        zcat P10.read2.fastq.gz | tail
            +
            BDD?@1111<@C@11<<1<1<<1C11@1G?11<F?1111<=/?E=?1111C1C111<F1<<111<1CC?C0C@@1<111<D11@11<111<<1<<FHGC
            @D00575:548:HTLKKBCX2:2:2216:21294:101002 2:N:0:ATCTTTAG
            GTCAGACTCCCAAGGTGGCCAAACAGGAAAAGAAGAAGAAGAAGACAGGCCGGGCCAAGAGGCGAATGCAGTACAACCGGCGCTTTGTCAATGTTGTGC
            +
            DDCBBIHHH@GFHEHHHIGHEHHHHIIEFGHHGHHHIHHHIIGGHIIIIIIIIIIIIIIHIEHFHHHIIIHHIIIHEHH?DHHHHIHHIIH?@DGEH=<
            @D00575:548:HTLKKBCX2:2:2216:21271:101030 2:N:0:ATCTTTAG
            GAAAAAAAAAAAAATTAAAAAAACAAGGTCCCTACACCGCTCCCTCCTTTTTAACAAGGAAGTTGAAATTTAGGGTTTCCTTTTCATCGGAACCCTGAA
            +
            DA@DBGDHD</C/CCG<<@CCDCCCH11<1<1<<CH11/</</1<@G@1CCF111<<11<11<1<1DC1<11111<10111<<11<111001/<<C11<
        conclusions:
        - no extraneous lines

----------------------
|     10/08/2020     |
----------------------

Objective: Data Exploration continued; 
Description: Review 10x Genomics Sequencing; Review Cell-Ranger

srun --account=bgmp --partition=bgmp --nodes=1 --ntasks-per-node=1 \
--time=2:00:00 --cpus-per-task=1 --pty bash

        squeue -u cchua
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
          13185261      bgmp     bash    cchua  R       0:05      1 n225

    F. Find number of records
        zcat P10.index.fq.gz | wc -l
            332566572

        zcat P10.read1.fastq.gz | wc -l
            1064991604

        zcat P10.read2.fastq.gz | wc -l
            timed out error -> rerun as a slurm script

            nano wc_read2.srun

                #!/bin/bash
                #SBATCH --account=bgmp
                #SBATCH --partition=bgmp
                #SBATCH --job-name=wc_read2_%j
                #SBATCH --output=wc_read2_%j.out
                #SBATCH --error=wc_read2_%j.err
                #SBATCH --time=0-23:59:59
                #SBATCH --nodes=1
                #SBATCH --ntasks-per-node=1
                #SBATCH --cpus-per-task=1

                dir="/projects/bgmp/shared/groups/2020/neuron_nerds/THE_DATA"

                /usr/bin/time -v zcat $dir/P10.read2.fastq.gz | wc -l

            sbatch wc_read2.srun

    G. Length of reads
        zcat P10.index.fq.gz | head -2 | tail -1 | wc -c
            9
            8 characters because of newline character

        zcat P10.read1.fastq.gz | head -2 | tail -1 | wc -c
            28
            27 characters

        zcat P10.read2.fastq.gz | head -2 | tail -1 | wc -c
            100
            99 characters

    H. Pull indices out of header line
        NOTE: Make this a slurm script and run in personal directory
        nano count_index.srun

            #!/bin/bash
            #SBATCH --account=bgmp
            #SBATCH --partition=bgmp
            #SBATCH --job-name=count_index_%j
            #SBATCH --output=count_index_%j.out
            #SBATCH --error=count_index_%j.err
            #SBATCH --time=0-23:59:59
            #SBATCH --nodes=1
            #SBATCH --ntasks-per-node=1
            #SBATCH --cpus-per-task=1

            dir="/projects/bgmp/shared/groups/2020/neuron_nerds/THE_DATA"

            /usr/bin/time -v | zcat $dir/P10.index.fq.gz | sed -n '1~4p' \
            | cut --delimiter=" " --fields=2 | cut --delimiter=":" --fields=4 \
            | sort | uniq -c > index_barcodes.txt

            /usr/bin/time -v | zcat $dir/P10.read1.fastq.gz | sed -n '1~4p' \
            | cut --delimiter=" " --fields=2 | cut --delimiter=":" --fields=4 \
            | sort | uniq -c > read1_barcodes.txt

            /usr/bin/time -v | zcat $dir/P10.read2.fastq.gz | sed -n '1~4p' \
            | cut --delimiter=" " --fields=2 | cut --delimiter=":" --fields=4 \
            | sort | uniq -c > read2_barcodes.txt

        sbatch count_index.srun

III. 10x Genomics Sequencing
    "make every cell count"
    A. How does the technology work
    B. What are the sequencing parameters

IV. CellRanger
    Link: https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/what-is-cell-ranger

    A. 4 pipelines:
        1. cellranger mkfastq - demultiplexes raw base call (BCL) files generated by Illumina sequencers into FASTQ files. 
        2. cellranger count - takes FASTQ files from cellranger mkfastq and performs alignment, filtering, barcode counting, and UMI counting.
        3. cellranger aggr - aggregates outputs from multiple runs of cellranger count, normalizing those runs to the same sequencing depth 
                            and then recomputing the feature-barcode matrices and analysis on the combined data. 
        4. cellranger reanalyze - takes feature-barcode matrices produced by cellranger count or cellranger aggr 
                            and reruns the dimensionality reduction, clustering, and gene expression algorithms using tunable parameter settings

----------------------
|     10/13/2020     |
----------------------

Chromium Single Cell 30 Library & Gel Bead Kit v2
26 bp Read1, 8 bp I7 Index and 98 bp Read2. 20000-50000 reads were obtained per cell.

WORKFLOW:
Single cell RNA-seq data were first analyzed by the Cell Ranger pipeline.
The UMI counts from different samples were combined in Seurat for further analysis (see below)
Cells expressing mOSN markers were further sub-clustered using a multi-kernel learning method, SIMLR (Wang et al., 2017). For OR expression analysis, only ORs with normalized expression above 2.5 we used.
For the GO term analysis, GO terms used in the analysis were from GO.db (Carlson, 2018). The enrichment was calculated by Goseq (Young et al., 2010). Enriched GO terms were connected by their hierarchies from GO.db and converted into gexf format using the rgexf function.
The GO term topographic map was visualized in Gephi (gephi.org). 
KEGG pathway analysis was done using Pathview (Luo and Brouwer, 2013).

STATISTICS:
Differential expression was called using the Wilcoxen rank sum test for each of the three mOSN clusters versus the other two mOSN clusters using Seurat’s FindMarkers function.
A Bonferroni correction was made based on the total number of genes in the dataset and was labeled as ‘‘p_val_adj’’ for the adjusted pvalue.
The proportion of cells in the primary cluster showing any expression for a gene was labeled as ‘‘pct.1’’ and the proportion in the two other clusters combined was labeled as ‘‘pct.2.’’ The average log fold change between the groupings was labeled ‘‘avg_logFC’’ with a positive value denoting a higher level of expression in the primary cluster and a negative value indicating a decreased expression level relative to the other two clusters. Only genes that pass an adjusted p-value cutoff of 0.05 were included in the list.
Data from Tan et al., 2016 were also used for the analysis. Differentially expressed genes were identified by two tailed Student’s t test. Genes with log2 fold change higher than 1 and log2 p-value larger than 5 were used to perform the GO term enrichment analysis.

CELL RANGER
Cell Ranger is a set of analysis pipelines that process Chromium single-cell RNA-seq output to align reads, generate feature-barcode matrices and perform clustering and gene expression analysis. Cell Ranger includes four pipelines relevant to single-cell gene expression experiments:
•	mkfastq demultiplexes raw base call (BCL) files generated by Illumina sequencers into FASTQ files. It is a wrapper around Illumina's bcl2fastq, with additional useful features that are specific to 10x libraries and a simplified sample sheet format.
•	count takes FASTQ files from cellranger mkfastq and performs alignment, filtering, barcode counting, and UMI counting. It uses the Chromium cellular barcodes to generate feature-barcode matrices, determine clusters, and perform gene expression analysis. The count pipeline can take input from multiple sequencing runs on the same GEM well. cellranger count also processes Feature Barcode data alongside Gene Expression reads.
•	aggr aggregates outputs from multiple runs of cellranger count, normalizing those runs to the same sequencing depth and then recomputing the feature-barcode matrices and analysis on the combined data. The aggr pipeline can be used to combine data from multiple samples into an experiment-wide feature-barcode matrix and analysis.
<- would this be useful in combating batch effect?
•	reanalyze takes feature-barcode matrices produced by cellranger count or cellranger aggr and reruns the dimensionality reduction, clustering, and gene expression algorithms using tunable parameter settings.
These pipelines combine Chromium-specific algorithms with the widely used RNA-seq aligner STAR. Output is delivered in standard BAM, MEX, CSV, HDF5 and HTML formats that are augmented with cellular information.

MKFASTQ
a pipeline that wraps Illumina's bcl2fastq and provides a number of convenient features in addition to the features of bcl2fastq:
-	Translates 10x sample index names into the corresponding oligonucleotides in the sample index.
-	Supports a simplified CSV samplesheet format to handle 10x use cases.
-	Generates sequencing and 10x-specific quality control metrics, including barcode quality, accuracy, and diversity.
-	Supports most bcl2fastq arguments, such as --use-bases-mask.
Do we have a Simple CSV Samplesheet for running cellranger mkfastq?

Example:
Lane,Sample,Index
1,test_sample,SI-TT-D9
CODE:
$ cellranger mkfastq --id=tiny-bcl \
                     --run=/path/to/tiny_bcl \
                     --csv=cellranger-tiny-bcl-simple-1.2.0.csv

COUNT
uses all of the cores available on your system to execute pipeline stages. 
--localcores=16 will limit cellranger to using up to sixteen cores at once.
 --localmem will restrict the amount of memory (in GB) used by cellranger.

CODE:
$ cellranger count --id=sample345 \
                   --transcriptome=/opt/refdata-gex-GRCh38-2020-A \
                   --fastqs=/home/jdoe/runs/HAWT7ADXX/outs/fastq_path \
                   --sample=mysample \
                   --expect-cells=1000 \
                   --localcores=8 \
                   --localmem=64

AGGR
Chemistry Batch Correction
Aggregate Targeted Gene Expression Data
Depth Normalization: automatically equalizes the average read depth per cell between groups before merging. This approach avoids artifacts that may be introduced due to differences in sequencing depth.

REANALYZE
PCA, nearest neighbors, TSNE
For example, More Principal Components and Clusters

----------------------
|     10/13/2020     |
----------------------

Seurat

downloaded seurat tutorial

1. need to download packages

install.packages("dplyr")
install.packages("Seurat")

----------------------
|     10/16/2020     |
----------------------

we were given fastq files so we do not need to run MKFASTQ

running counts pipeline

srun --account=bgmp --partition=bgmp --nodes=1 --ntasks-per-node=1 \
--time=2:00:00 --cpus-per-task=1 --pty bash

conda activate bgmp_py37

module spider cellranger

--------------------------------------------------------------------------------------------------------------------
  cellranger: cellranger/3.0.2
--------------------------------------------------------------------------------------------------------------------

    This module can be loaded directly: module load cellranger/3.0.2

conda activate bgmp_py37
module load cellranger/3.0.2

cellranger count --help
    /gpfs/packages/cellranger/3.0.2/cellranger-cs/3.0.2/bin
    cellranger count (3.0.2)
    Copyright (c) 2019 10x Genomics, Inc.  All rights reserved.
    -------------------------------------------------------------------------------

    'cellranger count' quantifies single-cell gene expression.

    The commands below should be preceded by 'cellranger':

    Usage:
        count
            --id=ID
            [--fastqs=PATH]
            [--sample=PREFIX]
            --transcriptome=DIR
            [options]
        count <run_id> <mro> [options]
        count -h | --help | --version

    Arguments:
        id      A unique run id, used to name output folder [a-zA-Z0-9_-]+.
        fastqs  Path of folder created by mkfastq or bcl2fastq.
        sample  Prefix of the filenames of FASTQs to select.
        transcriptome   Path of folder containing 10x-compatible reference.

    Options:
    # Single Cell Gene Expression
        --description=TEXT  Sample description to embed in output files.
        --libraries=CSV     CSV file declaring input library data sources.
        --expect-cells=NUM  Expected number of recovered cells.
        --force-cells=NUM   Force pipeline to use this number of cells, bypassing
                                the cell detection algorithm.
        --feature-ref=CSV   Feature reference CSV file, declaring feature-barcode
                                constructs and associated barcodes.
        --nosecondary       Disable secondary analysis, e.g. clustering. Optional.
        --r1-length=NUM     Hard trim the input Read 1 to this length before
                                analysis.
        --r2-length=NUM     Hard trim the input Read 2 to this length before
                                analysis.
        --chemistry=CHEM    Assay configuration. NOTE: by default the assay
                                configuration is detected automatically, which
                                is the recommened mode. You usually will not need
                                to specify a chemistry. Options are: 'auto' for
                                autodetection, 'threeprime' for Single Cell 3',
                                'fiveprime' for  Single Cell 5', 'SC3Pv1' or
                                'SC3Pv2' or 'SC3Pv3' for Single Cell 3' v1/v2/v3,
                                'SC5P-PE' or 'SC5P-R2' for Single Cell 5'.
                                paired-end/R2-only. Default: auto.
        --no-libraries      Proceed with processing using a --feature-ref but no
                                feature-barcoding data specified with the
                                'libraries' flag.
        --lanes=NUMS        Comma-separated lane numbers.
        --indices=INDICES   Comma-separated sample index set "SI-001" or sequences.
        --project=TEXT      Name of the project folder within a mkfastq or
                                bcl2fastq-generated folder to pick FASTQs from.

    # Martian Runtime
        --jobmode=MODE      Job manager to use. Valid options:
                                local (default), sge, lsf, or a .template file
        --localcores=NUM    Set max cores the pipeline may request at one time.
                                Only applies when --jobmode=local.
        --localmem=NUM      Set max GB the pipeline may request at one time.
                                Only applies when --jobmode=local.
        --mempercore=NUM    Set max GB each job may use at one time.
                                Only applies in cluster jobmodes.
        --maxjobs=NUM       Set max jobs submitted to cluster at one time.
                                Only applies in cluster jobmodes.
        --jobinterval=NUM   Set delay between submitting jobs to cluster, in ms.
                                Only applies in cluster jobmodes.
        --overrides=PATH    The path to a JSON file that specifies stage-level
                                overrides for cores and memory.  Finer-grained
                                than --localcores, --mempercore and --localmem.
                                Consult the 10x support website for an example
                                override file.
        --uiport=PORT       Serve web UI at http://localhost:PORT
        --disable-ui        Do not serve the UI.
        --noexit            Keep web UI running after pipestance completes or fails.
        --nopreflight       Skip preflight checks.

        -h --help           Show this message.
        --version           Show version.

    Note: 'cellranger count' can be called in two ways, depending on how you
    demultiplexed your BCL data into FASTQ files.

    1. If you demultiplexed with 'cellranger mkfastq' or directly with
    Illumina bcl2fastq, then set --fastqs to the project folder containing
    FASTQ files. In addition, set --sample to the name prefixed to the FASTQ
    files comprising your sample. For example, if your FASTQs are named:
        subject1_S1_L001_R1_001.fastq.gz
    then set --sample=subject1

    2. If you demultiplexed with 'cellranger demux', then set --fastqs to a
    demux output folder containing FASTQ files. Use the --lanes and --indices
    options to specify which FASTQ reads comprise your sample.
    This method is deprecated. Please use 'cellranger mkfastq' going forward.

cellranger count --id=sample345 \
                   --transcriptome=/opt/refdata-gex-GRCh38-2020-A \
                   --fastqs=/home/jdoe/runs/HAWT7ADXX/outs/fastq_path \
                   --sample=mysample \
                   --expect-cells=1000 \
                   --localcores=8 \
                   --localmem=64

cellranger count --id=P10_test \
--fastqs=/projects/bgmp/shared/groups/2020/neuron_nerds/THE_DATA \
--sample=P10 \
--transcriptome=/projects/bgmp/shared/groups/2020/neuron_nerds/refdata-gex-mm10-2020-A \
--localcores=8 \
--localmem=64 \


--r1-length=NUM     Hard trim the input Read 1 to this length before
                    analysis.
--r2-length=NUM     Hard trim the input Read 2 to this length before
                    analysis
--indices=INDICES   Comma-separated sample index set "SI-001" or sequences.

tar -xzvf cellranger-4.0.0.tar.gz <- talapas already has the program on it

https://support.10xgenomics.com/single-cell-gene-expression/software/downloads/latest?
wget https://cf.10xgenomics.com/supp/cell-exp/refdata-gex-mm10-2020-A.tar.gz

md5sum: 886eeddde8731ffb58552d0bb81f533d

check:

md5sum refdata-gex-mm10-2020-A.tar.gz
886eeddde8731ffb58552d0bb81f533d  refdata-gex-mm10-2020-A.tar.gz

gunzip refdata-gex-mm10-2020-A.tar.gz <- do not need to do this
tar -xzvf refdata-gex-mm10-2020-A.tar.gz

Reference Build Notes:
https://support.10xgenomics.com/single-cell-gene-expression/software/release-notes/build#mm10_2020A

    # Genome metadata
    genome="mm10"
    version="2020-A"


    # Set up source and build directories
    build="mm10-2020-A_build"
    mkdir -p "$build"


    # Download source files if they do not exist in reference_sources/ folder
    source="reference_sources"
    mkdir -p "$source"


    fasta_url="http://ftp.ensembl.org/pub/release-98/fasta/mus_musculus/dna/Mus_musculus.GRCm38.dna.primary_assembly.fa.gz"
    fasta_in="${source}/Mus_musculus.GRCm38.dna.primary_assembly.fa"
    gtf_url="http://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M23/gencode.vM23.primary_assembly.annotation.gtf.gz"
    gtf_in="${source}/gencode.vM23.primary_assembly.annotation.gtf"


    if [ ! -f "$fasta_in" ]; then
        curl -sS "$fasta_url" | zcat > "$fasta_in"
    fi
    if [ ! -f "$gtf_in" ]; then
        curl -sS "$gtf_url" | zcat > "$gtf_in"
    fi


    # Modify sequence headers in the Ensembl FASTA to match the file
    # "GRCm38.primary_assembly.genome.fa" from GENCODE. Unplaced and unlocalized
    # sequences such as "GL456210.1" have the same names in both versions.
    #
    # Input FASTA:
    #   >1 dna:chromosome chromosome:GRCm38:1:1:195471971:1 REF
    #
    # Output FASTA:
    #   >chr1 1
    fasta_modified="$build/$(basename "$fasta_in").modified"
    # sed commands:
    # 1. Replace metadata after space with original contig name, as in GENCODE
    # 2. Add "chr" to names of autosomes and sex chromosomes
    # 3. Handle the mitochrondrial chromosome
    cat "$fasta_in" \
        | sed -E 's/^>(\S+).*/>\1 \1/' \
        | sed -E 's/^>([0-9]+|[XY]) />chr\1 /' \
        | sed -E 's/^>MT />chrM /' \
        > "$fasta_modified"


    # Remove version suffix from transcript, gene, and exon IDs in order to match
    # previous Cell Ranger reference packages
    #
    # Input GTF:
    #     ... gene_id "ENSMUSG00000102693.1"; ...
    # Output GTF:
    #     ... gene_id "ENSMUSG00000102693"; gene_version "1"; ...
    gtf_modified="$build/$(basename "$gtf_in").modified"
    # Pattern matches Ensembl gene, transcript, and exon IDs for human or mouse:
    ID="(ENS(MUS)?[GTE][0-9]+)\.([0-9]+)"
    cat "$gtf_in" \
        | sed -E 's/gene_id "'"$ID"'";/gene_id "\1"; gene_version "\3";/' \
        | sed -E 's/transcript_id "'"$ID"'";/transcript_id "\1"; transcript_version "\3";/' \
        | sed -E 's/exon_id "'"$ID"'";/exon_id "\1"; exon_version "\3";/' \
        > "$gtf_modified"


    # Define string patterns for GTF tags
    # NOTES:
    # - Since GENCODE release 31/M22 (Ensembl 97), the "lincRNA" and "antisense"
    #   biotypes are part of a more generic "lncRNA" biotype.
    # - These filters are relevant only to GTF files from GENCODE. The GTFs from
    #   Ensembl release 98 have the following differences:
    #   - The names "gene_biotype" and "transcript_biotype" are used instead of
    #     "gene_type" and "transcript_type".
    #   - Readthrough transcripts are present but are not marked with the
    #     "readthrough_transcript" tag.
    BIOTYPE_PATTERN=\
    "(protein_coding|lncRNA|\
    IG_C_gene|IG_D_gene|IG_J_gene|IG_LV_gene|IG_V_gene|\
    IG_V_pseudogene|IG_J_pseudogene|IG_C_pseudogene|\
    TR_C_gene|TR_D_gene|TR_J_gene|TR_V_gene|\
    TR_V_pseudogene|TR_J_pseudogene)"
    GENE_PATTERN="gene_type \"${BIOTYPE_PATTERN}\""
    TX_PATTERN="transcript_type \"${BIOTYPE_PATTERN}\""
    READTHROUGH_PATTERN="tag \"readthrough_transcript\""


    # Construct the gene ID allowlist. We filter the list of all transcripts
    # based on these criteria:
    #   - allowable gene_type (biotype)
    #   - allowable transcript_type (biotype)
    #   - no "readthrough_transcript" tag
    # We then collect the list of gene IDs that have at least one associated
    # transcript passing the filters.
    cat "$gtf_modified" \
        | awk '$3 == "transcript"' \
        | grep -E "$GENE_PATTERN" \
        | grep -E "$TX_PATTERN" \
        | grep -Ev "$READTHROUGH_PATTERN" \
        | sed -E 's/.*(gene_id "[^"]+").*/\1/' \
        | sort \
        | uniq \
        > "${build}/gene_allowlist"


    # Filter the GTF file based on the gene allowlist
    gtf_filtered="${build}/$(basename "$gtf_in").filtered"
    # Copy header lines beginning with "#"
    grep -E "^#" "$gtf_modified" > "$gtf_filtered"
    # Filter to the gene allowlist
    grep -Ff "${build}/gene_allowlist" "$gtf_modified" \
        >> "$gtf_filtered"


    # Create reference package
    cellranger mkref --ref-version="$version" \
        --genome="$genome" --fasta="$fasta_modified" --genes="$gtf_filtered"

nano count_test.srun

    #!/bin/bash
    #SBATCH --account=bgmp
    #SBATCH --partition=bgmp
    #SBATCH --job-name=count_test_%j
    #SBATCH --output=count_test_%j.out
    #SBATCH --error=count_test_%j.err
    #SBATCH --time=1-23:59:59
    #SBATCH --nodes=1
    #SBATCH --ntasks-per-node=1
    #SBATCH --cpus-per-task=8
    #SBATCH --mem=64GB

    conda activate bgmp_py37
    module load cellranger/3.0.2

    dir="/projects/bgmp/shared/groups/2020/neuron_nerds"

    /usr/bin/time -v cellranger count --id=P10_test \
    --fastqs=$dir/THE_DATA \
    --sample=P10 \
    --transcriptome=$dir/refdata-gex-mm10-2020-A \
    --localcores=8 \
    --localmem=64

sbatch count_test.srun

** need to trim the last nucleotide off of read 1 says Max

^ would we need to check for adapter trimming?

sed '2~4s/(.)$//' myfile > newfile
Translated that says: starting from line 2, substitute the first 4 characters every 4th line with nothing (i.e. remove them).

zcat P10_S1_L001_R1_001.fastq.gz | head | sed '2~4s/[ATCGN]$//' | sed '4~4s/[!-J]$//'

OUTPUT FROM CELLRANGER COUNT pipeline

/gpfs/packages/cellranger/3.0.2/cellranger-cs/3.0.2/bin
cellranger count (3.0.2)
Copyright (c) 2019 10x Genomics, Inc.  All rights reserved.
-------------------------------------------------------------------------------

Martian Runtime - '3.0.2-v3.2.0'
Serving UI at http://n225:42310?auth=niLJWFrDmPP5TRlOr2hF40fyb8gJ4Z1KwAwPmFe8QbA

Running preflight checks (please wait)...
2020-10-16 12:08:25 [runtime] (ready)           ID.P10_test.SC_RNA_COUNTER_CS.EXPAND_SAMPLE_DEF
2020-10-16 12:08:25 [runtime] (run:local)       ID.P10_test.SC_RNA_COUNTER_CS.EXPAND_SAMPLE_DEF.fork0.chnk0.main
2020-10-16 12:08:32 [runtime] (chunks_complete) ID.P10_test.SC_RNA_COUNTER_CS.EXPAND_SAMPLE_DEF
Checking sample info...
Checking FASTQ folder...
Checking reference...
Checking reference_path (/projects/bgmp/shared/groups/2020/neuron_nerds/refdata-gex-mm10-2020-A) on n225...
Checking chemistry...
Checking optional arguments...
mrc: '3.0.2-v3.2.0'

mrp: '3.0.2-v3.2.0'

Anaconda: Python 2.7.14 :: Anaconda, Inc.

numpy: 1.14.2

scipy: 1.0.1

pysam: 0.14.1

h5py: 2.8.0

pandas: 0.22.0

STAR: STAR_2.5.1b

samtools: samtools 1.7
Using htslib 1.7
Copyright (C) 2018 Genome Research Ltd.

2020-10-16 12:08:33 [runtime] (ready)           ID.P10_test.SC_RNA_COUNTER_CS.SC_RNA_COUNTER.DISABLE_FEATURE_STAGES
...

Outputs:
- Run summary HTML:                         /projects/bgmp/shared/groups/2020/neuron_nerds/test/P10_test/outs/web_summary.html
- Run summary CSV:                          /projects/bgmp/shared/groups/2020/neuron_nerds/test/P10_test/outs/metrics_summary.csv
- BAM:                                      /projects/bgmp/shared/groups/2020/neuron_nerds/test/P10_test/outs/possorted_genome_bam.bam
- BAM index:                                /projects/bgmp/shared/groups/2020/neuron_nerds/test/P10_test/outs/possorted_genome_bam.bam.bai
- Filtered feature-barcode matrices MEX:    /projects/bgmp/shared/groups/2020/neuron_nerds/test/P10_test/outs/filtered_feature_bc_matrix
- Filtered feature-barcode matrices HDF5:   /projects/bgmp/shared/groups/2020/neuron_nerds/test/P10_test/outs/filtered_feature_bc_matrix.h5
- Unfiltered feature-barcode matrices MEX:  /projects/bgmp/shared/groups/2020/neuron_nerds/test/P10_test/outs/raw_feature_bc_matrix
- Unfiltered feature-barcode matrices HDF5: /projects/bgmp/shared/groups/2020/neuron_nerds/test/P10_test/outs/raw_feature_bc_matrix.h5
- Secondary analysis output CSV:            /projects/bgmp/shared/groups/2020/neuron_nerds/test/P10_test/outs/analysis
- Per-molecule read information:            /projects/bgmp/shared/groups/2020/neuron_nerds/test/P10_test/outs/molecule_info.h5
- CRISPR-specific analysis:                 null
- Loupe Cell Browser file:                  /projects/bgmp/shared/groups/2020/neuron_nerds/test/P10_test/outs/cloupe.cloupe

Waiting 6 seconds for UI to do final refresh.
Pipestance completed successfully!

2020-10-16 17:20:18 Shutting down.
Saving pipestance info to P10_test/P10_test.mri.tgz

----------------------
|     10/22/2020     |
----------------------

Objective: How to run rstudio in talapas
description: copy of meeting notes with Pete 

Create an interactive node by entering talapas-ln1.uoregon.edu in web browser
Select talapas desktop under interactive apps dropdown
Submit number of resources needed
Launch  noVNC in new tab
Open terminal from the icon in the top left

ml rstudio
module spider R
ml <latest version>
rstudio

Download packages which should live in your environment

Next, reviewed the results from Cellranger counts with Pete:
Overall, everything is as expected
Saturation should be greater than 90% (but okay if it isn’t). Saturation means the number of duplicate reads 
The assay is optimized for 10K cells
It is okay that the version number are different between ours and the Yu lab’s (Pete would use the latest version)
We can take the filtered and raw counts into seurat (Pete takes the raw counts)

Suggestions:
- Email Max to ask why we have less reads than what is in their html file
- Possibly run fastq files through FASTQC?
- Align raw reads to genome to see if reads are aligning to more than one place
    - Because cellranger count does not save reads that map to more than one place
- Explore differences between filtered and raw counts
- Run both through seurat

----------------------
|     10/25/2020     |
----------------------

Objective: Run FASTQC on fastq files

/projects/bgmp/shared/groups/2020/neuron_nerds/chris

# log onto Talapas
ssh cchua@talapas-ln1.uoregon.edu

# set-up an interactive run in Talapas
srun --account=bgmp --partition=bgmp --nodes=1 --ntasks-per-node=1 \
--time=2:00:00 --cpus-per-task=1 --pty bash

# activate base
conda activate bgmp_py37

# load module to check for dependencies
module load fastqc/0.11.5

# make a directory for fastqc files
mkdir fastqc_output
cd fastqc_output

# create slurm script for 11_2H
nano fastqc_P10_untrimmed.srun

#!/bin/bash
#SBATCH --account=bgmp
#SBATCH --partition=bgmp
#SBATCH --job-name=fastqc_P10_untrimmed_%j
#SBATCH --output=fastqc_P10_untrimmed_%j.out
#SBATCH --error=fastqc_P10_untrimmed_%j.err
#SBATCH --time=1-23:59:59
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1
#SBATCH --cpus-per-task=6

module load fastqc/0.11.5

dir1="/projects/bgmp/shared/groups/2020/neuron_nerds/THE_DATA"
dir2="/projects/bgmp/shared/groups/2020/neuron_nerds/chris"

/usr/bin/time -v fastqc \
-o $dir2/fastqc_output/ \
--noextract \
-f fastq \
-t 6 \
$dir1/P10_S1_L001_R1_001.fastq.gz \
$dir1/P10_S1_L001_R2_001.fastq.gz

sbatch fastqc_P10_untrimmed.srun

Looking at the overrepresented sequences, there appears to be contamination of a repetative sequence

Sequence	Count	Percentage	Possible Source
AAGCAGTGGTATCAACGCAGAGTACATGGGAGGCATTCAGGCAGCGAGAG	350540	0.1316592539071322	No Hit
AAGCAGTGGTATCAACGCAGAGTACATGGGGAGGCATTCAGGCAGCGAGA	278293	0.10452401651046256	No Hit

It's adapter contamination, 30-bp TSO sequence: 
AAGCAGTGGTATCAACGCAGAGTACATGGG
AAGCAGTGGTATCAACGCAGAGTACATGGGAAGCAGTGGTATCAACGCAG
AAGCAGTGGTATCAACGCAGAGTACATGGG AAGCAGTGGTATCAACGCA

zcat P10_S1_L001_R2_001.fastq.gz | sed -n '2~4p' | grep "^AAGCAGTGGTATCAACGCAGAGTACATGGG" | head
AAGCAGTGGTATCAACGCAGAGTACATGGGAACCCACTAACACACTATAGCAGTACTTTTATAAAGCAGGACAAAAGACAATATCTACATGGTGCTAAA
AAGCAGTGGTATCAACGCAGAGTACATGGGAGATGACAAAGTACCTTGGACTGAATCACACGGAGACAGCATTTTGAGCAGAACGCAGGCTAAACTCTT
AAGCAGTGGTATCAACGCAGAGTACATGGGATCTGCTGGAGTTCTACGTTTTTATGTAAGCATGAAACACAGGCAGTGTGAGAGAAAGCCAGGACCCGA
AAGCAGTGGTATCAACGCAGAGTACATGGGGCTCTCTTGCTCTGCGCTCTGACGCTCTGGCGCTCTGGCTTCTAGAGATGTAAGCGGGGGGCTTTCGTT
AAGCAGTGGTATCAACGCAGAGTACATGGGGACTTTGGATAGTCAGTGAAGGTTAAATCCTGCTGTCAGAAACTCCCCTGCTGTTCGAATTTTTCTTAC
AAGCAGTGGTATCAACGCAGAGTACATGGGAAGGTGAAGAAAAAGCTGTTAGAGAAGATAGGAAAATAGAAGACAAAGCATCTTTAGAAGACAGAAAAG
AAGCAGTGGTATCAACGCAGAGTACATGGGGTGTTTCAGGAGAGCTAGGGGTACACAGAAAGACTTACCTGAAACCATACTGCCGAAATAAGGGGGCGG
AAGCAGTGGTATCAACGCAGAGTACATGGGAAAGACTTTGTTTTAAACTTTAAAACCAATTTAATAGTGGCAGTGGAATTTGAATCTTGTTCACAAATC
AAGCAGTGGTATCAACGCAGAGTACATGGGGTAATGATCCAGGGCAGCGGAACGGGGTGACCCTGAGTATTGAGACCCTGCAGCGATGCTGAGCAGGTT
AAGCAGTGGTATCAACGCAGAGTACATGGGGAGCTGGAGAGATGGCTCAGCCGTTAAAGGCTAGGCTCACAACCAAAAAAAAAAAAAAAAAAAAAAAAA

zcat P10_S1_L001_R2_001.fastq.gz | sed -n '2~4p' | grep "^AAGCAGTGGTATCAACGCAGAGTACATGGG" | wc -l
5042143

Looking at per base sequence content, there appears to be higher A's and T's percentages in that order. Is there polyA contamination?

zcat P10_S1_L001_R2_001.fastq.gz | sed -n '2~4p' | grep "AAAAAAAAAAAAAAAAA$" | head
ATTGTACCTATTTTGTATATGTGAGATGTTTAAATAAATTGTGAAAAATAAAATAAAGCATTTTGGTTTTCCAAAAGAAAAAAAAAAAAAAAAAAAAAA
AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
GCTTATTCAAAAGAACTTCTCTAAAGCTCCCTGCTTTTTTAGAGTGGGACTAAGGCCCACAATCTACAGCCACTTTCACAAAAAAAAAAAAAAAAAAAA
GAAACTAAAAAACAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
GTCAGTCTTGTTCCATCCTGTCCTGAGGGCCCCCACTCTGTCTCCTCTGCTCTTTCTAATAAACAGCAGTTGCATTAAAAAAAAAAAAAAAAAAAAAAA
ATTTGTGAATGGAATGCCTTGTAATATGAATGTTAATATAATATGTAAAGGGAGATTAAACGTTTGAATGATTATCCCAAAAAAAAAAAAAAAAAAAAA
GGCCCTGGCTTTAGGTTGTCAGGGGATTAAACAGCTTTTCATACTCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
ACTGCTGCCTCCTCAGCCATTATAGATTGTAACCTCTGAAACCGTGAGCCAAAATAAACCTTACCTCCCTTGAAAAAAAAAAAAAAAAAAAAAAAAAAA
CCTATTCTCTGGGGGAATTTGAAGAAATGCTTGAATATTTCCAGTACTGGGAACAAATAAATAACACTATAATTTTCAAAAAAAAAAAAAAAAAAAAAA
GCTGTAGAAACTTCTGTCGCCCTGGGTAGAGTAAATTTTTTAAATGGCTAAGATATTACAGACACTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA

zcat P10_S1_L001_R2_001.fastq.gz | sed -n '2~4p' | grep "AAAAAAAAAAAAAAAAA$" | wc -l
3817785

https://github.com/10XGenomics/cellranger/issues/46
"In CellRanger v4 they have actually changed the behviour-- "When analyzing 3’ Gene Expression data, 
Cell Ranger 4.0 trims the template switch oligo (TSO) sequence from the 5’ end of Read-2 and 
the poly-A sequence from the 3’ end before aligning reads to the reference transcriptome. 
This behavior is different from Cell Ranger 3.1, which does not perform any trimming.

A full length cDNA molecule is normally flanked by the 30-bp TSO sequence, AAGCAGTGGTATCAACGCAGAGTACATGGG, 
at the 5' end and the poly-A sequence at the 3' end. Some fraction of sequencing reads are expected to 
contain either or both of these sequences, depending on the fragment size distribution of the library. 
Reads derived from short RNA molecules are more likely to contain either or both TSO and poly-A sequence than longer RNA molecules.

Trimming results in better alignment, with the fraction of reads mapped to a gene increasing by up to 1.5%, 
because the presence of non-template sequence in the form of either TSO or poly-A confounds read mapping. 
Trimming improves the sensitivity of the assay as well as the computational efficiency of the pipeline. 
Tags ts:i and pa:i in the output BAM files indicate the number of TSO nucleotides trimmed from the 5' end 
of Read-2 and the number of poly-A nucleotides trimmed from the 3' end. The trimmed bases are present in 
the sequence of the BAM record and are soft clipped in the CIGAR string.

Below, we illustrate how the fraction of reads mapped confidently to the transcriptome varies for both 
trimmed and untrimmed alignment as a function of read-length for a variety of sample types." 
https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/release-notes"

conclusions:
adapter/polyA contamination. Is there so much that we need to trim and redo counts?

----------------------
|     10/25/2020     |
----------------------

Objective: Explore difference between raw and filtered counts matrix

less trimmed_count_13250720.err
    Command being timed: "cellranger count --id=Trimmed_count --fastqs=/projects/bgmp/shared/groups/2020/neuron_nerds/THE_DATA/TRIMMED_FASTQs --sample=P10Trimmed --transcriptome=/projects/bgmp/shared/groups/2020/neuron_nerds/refdata-gex-mm10-2020-A --localcores=8 --localmem=64"
        User time (seconds): 98237.60
        System time (seconds): 4029.19
        Percent of CPU this job got: 580%
        Elapsed (wall clock) time (h:mm:ss or m:ss): 4:53:31
        Average shared text size (kbytes): 0
        Average unshared data size (kbytes): 0
        Average stack size (kbytes): 0
        Average total size (kbytes): 0
        Maximum resident set size (kbytes): 12569408
        Average resident set size (kbytes): 0
        Major (requiring I/O) page faults: 0
        Minor (reclaiming a frame) page faults: 617113875
        Voluntary context switches: 88025920
        Involuntary context switches: 419972
        Swaps: 0
        File system inputs: 0
        File system outputs: 144
        Socket messages sent: 0
        Socket messages received: 0
        Signals delivered: 0
        Page size (bytes): 4096
        Exit status: 0

tail -20 trimmed_count_13250720.out
    Outputs:
    - Run summary HTML:                         /projects/bgmp/shared/groups/2020/neuron_nerds/Trimmed_count/outs/web_summary.html
    - Run summary CSV:                          /projects/bgmp/shared/groups/2020/neuron_nerds/Trimmed_count/outs/metrics_summary.csv
    - BAM:                                      /projects/bgmp/shared/groups/2020/neuron_nerds/Trimmed_count/outs/possorted_genome_bam.bam
    - BAM index:                                /projects/bgmp/shared/groups/2020/neuron_nerds/Trimmed_count/outs/possorted_genome_bam.bam.bai
    - Filtered feature-barcode matrices MEX:    /projects/bgmp/shared/groups/2020/neuron_nerds/Trimmed_count/outs/filtered_feature_bc_matrix
    - Filtered feature-barcode matrices HDF5:   /projects/bgmp/shared/groups/2020/neuron_nerds/Trimmed_count/outs/filtered_feature_bc_matrix.h5
    - Unfiltered feature-barcode matrices MEX:  /projects/bgmp/shared/groups/2020/neuron_nerds/Trimmed_count/outs/raw_feature_bc_matrix
    - Unfiltered feature-barcode matrices HDF5: /projects/bgmp/shared/groups/2020/neuron_nerds/Trimmed_count/outs/raw_feature_bc_matrix.h5
    - Secondary analysis output CSV:            /projects/bgmp/shared/groups/2020/neuron_nerds/Trimmed_count/outs/analysis
    - Per-molecule read information:            /projects/bgmp/shared/groups/2020/neuron_nerds/Trimmed_count/outs/molecule_info.h5
    - CRISPR-specific analysis:                 null
    - Loupe Cell Browser file:                  /projects/bgmp/shared/groups/2020/neuron_nerds/Trimmed_count/outs/cloupe.cloupe

    Waiting 6 seconds for UI to do final refresh.
    Pipestance completed successfully!

    2020-10-17 20:34:49 Shutting down.
    Saving pipestance info to Trimmed_count/Trimmed_count.mri.tgz

cd /projects/bgmp/shared/groups/2020/neuron_nerds/Trimmed_count/outs/filtered_feature_bc_matrix

    zcat barcodes.tsv.gz | head -1
    AAACCTGAGCATGGCA-1

    zcat features.tsv.gz | head -1
    ENSMUSG00000051951      Xkr4    Gene Expression

    zcat matrix.mtx.gz | head -3
    %%MatrixMarket matrix coordinate integer general
    %metadata_json: {"format_version": 2, "software_version": "3.0.2"}
    32285 9031 15711877

    zcat matrix.mtx.gz | wc -l
    15711880

cd /projects/bgmp/shared/groups/2020/neuron_nerds/Trimmed_count/outs/raw_feature_bc_matrix

    zcat barcodes.tsv.gz | head -1
    AAACCTGAGAAACCAT-1

    zcat features.tsv.gz | head -1
    ENSMUSG00000051951      Xkr4    Gene Expression

    zcat matrix.mtx.gz | head -3
    %%MatrixMarket matrix coordinate integer general
    %metadata_json: {"format_version": 2, "software_version": "3.0.2"}
    32285 737280 31891870

    zcat matrix.mtx.gz | wc -l
    31891873

----------------------
|     10/25/2020     |
----------------------

perform trimming -> align to transcriptome -> see number of hits
-> redo cellranger counts

Matt already downloaded Cellranger version 4 in this location (/projects/bgmp/shared/groups/2020/neuron_nerds/CellRanger) already, but here is the command:
    wget -O cellranger-4.0.0.tar.gz "https://cf.10xgenomics.com/releases/cell-exp/cellranger-4.0.0.tar.gz?Expires=1603687842&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZi4xMHhnZW5vbWljcy5jb20vcmVsZWFzZXMvY2VsbC1leHAvY2VsbHJhbmdlci00LjAuMC50YXIuZ3oiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE2MDM2ODc4NDJ9fX1dfQ__&Signature=n0BNaBJ6sPBgNd7lwZOCcYtJFHEQmzKshGjGl2E~AaRGGROu9Jk1i9dujdWjNmscnCKuTnXxZwXbZ~-l5SKLgmlM-QkC-jTQdd42V1fv0HsS3nQJZlobanaF57g2jnTh9JPF49naBKQ5sOlQ3y8Ok7-HfOTo8oDRR2BeG22SCcCg9tjCnJYiGDvJ5m-f1MfbJrkrRw72FZTiw2ISZcMD4MJDtptG1ciPrt5LV7EH2I50k3-aI7VvYIuvege4D0T~OqN86mDSlmjxPZpnF1-wi7oJKu64~fvMcnd74~W2hxYBFm~Uk27uIs1OtMevUo439GcwInrrgIPUrU-Hb~Bvyw__&Key-Pair-Id=APKAI7S6A5RYOXBWRPDA"

pwd 
/projects/bgmp/shared/groups/2020/neuron_nerds/chris

nano cellrangerV4_counts.sh

#!/usr/bin/env bash

#SBATCH --job-name=cellrangerV4_count_%j
#SBATCH --account=bgmp
#SBATCH --partition=bgmp
#SBATCH --output=cellrangerV4_count_%j.out
#SBATCH --error=cellrangerV4_count_%j.err
#SBATCH --time=1-23:59:59
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1
#SBATCH --cpus-per-task=8
#SBATCH --mem=64G

conda activate bgmp_py37

dir="/projects/bgmp/shared/groups/2020/neuron_nerds"

/usr/bin/time -v \
$dir/CellRanger/cellranger-4.0.0/bin/cellranger count \
--id=Trimmed_count \
--fastqs=$dir/THE_DATA/TRIMMED_FASTQs \
--sample=P10Trimmed \
--transcriptome=$dir/refdata-gex-mm10-2020-A \
--localcores=8 \
--localmem=64

sbatch cellrangerV4_count.sh

 tail -20 cellrangerV4_count_13393123.out
Outputs:
- Run summary HTML:                         /projects/bgmp/shared/groups/2020/neuron_nerds/chris/Trimmed_count/outs/web_summary.html
- Run summary CSV:                          /projects/bgmp/shared/groups/2020/neuron_nerds/chris/Trimmed_count/outs/metrics_summary.csv
- BAM:                                      /projects/bgmp/shared/groups/2020/neuron_nerds/chris/Trimmed_count/outs/possorted_genome_bam.bam
- BAM index:                                /projects/bgmp/shared/groups/2020/neuron_nerds/chris/Trimmed_count/outs/possorted_genome_bam.bam.bai
- Filtered feature-barcode matrices MEX:    /projects/bgmp/shared/groups/2020/neuron_nerds/chris/Trimmed_count/outs/filtered_feature_bc_matrix
- Filtered feature-barcode matrices HDF5:   /projects/bgmp/shared/groups/2020/neuron_nerds/chris/Trimmed_count/outs/filtered_feature_bc_matrix.h5
- Unfiltered feature-barcode matrices MEX:  /projects/bgmp/shared/groups/2020/neuron_nerds/chris/Trimmed_count/outs/raw_feature_bc_matrix
- Unfiltered feature-barcode matrices HDF5: /projects/bgmp/shared/groups/2020/neuron_nerds/chris/Trimmed_count/outs/raw_feature_bc_matrix.h5
- Secondary analysis output CSV:            /projects/bgmp/shared/groups/2020/neuron_nerds/chris/Trimmed_count/outs/analysis
- Per-molecule read information:            /projects/bgmp/shared/groups/2020/neuron_nerds/chris/Trimmed_count/outs/molecule_info.h5
- CRISPR-specific analysis:                 null
- Loupe Browser file:                       /projects/bgmp/shared/groups/2020/neuron_nerds/chris/Trimmed_count/outs/cloupe.cloupe
- Feature Reference:                        null
- Target Panel File:                        null

Waiting 6 seconds for UI to do final refresh.
Pipestance completed successfully!

2020-10-25 14:29:57 Shutting down.

compared to v3, v4 has 20 less cells detected and 15 less genes per cell, but about 60 more reads per cell.
We got higher sequencing saturation by 1% and 0.3% more mapped to the genome with 0.4% greater confidence. 
Most importantly, we got tighter clusters. 

Used the v4 counts for seurat

----------------------
|     10/26/2020     |
----------------------

Objective: Run raw and filtered counts through seurat

interactive desktop

ml rstudio
module spider R
ml R/4.0.2
rstudio

saved rmarkdown as "analyze_counts" in my folder

install.packages("dplyr")
install.packages("Seurat")
install.packages("patchwork")

followed the vignette here:https://satijalab.org/seurat/v3.2/pbmc3k_tutorial.html

used 20 clusters

see rmarkdown html file for more information

to-do: 
- see if results correlate with what Alyx got
- see of the clusters have biological significance

----------------------
|     10/27/2020     |
----------------------

Email from Max:

"The P10 subset of our age-wise olfactory epithelial RNA-seq data is unique in that it contains FASTQ files from two flow-cells. 
Previously, I included reads from only one flow cell...The newly uploaded files in the OneDrive folder are concatenated across both lanes in both flow-cells."

--> need to consider batch effect now

http://www.bioconductor.org/packages/release/bioc/html/batchelor.html 

if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

BiocManager::install("batchelor")

https://rdrr.io/bioc/batchelor/man/mnnCorrect.html

library(batchelor)

B1 <- matrix(rnorm(10000), ncol=50) # Batch 1 
B2 <- matrix(rnorm(10000), ncol=50) # Batch 2
out <- mnnCorrect(B1, B2) # corrected values

waiting for Max to finish the sync with the google drive.

----------------------
|     10/31/2020     |
----------------------

Redid counts on the full dataset

pwd 
/projects/bgmp/shared/groups/2020/neuron_nerds/chris

nano counts_fulldata.sh

#!/usr/bin/env bash

#SBATCH --job-name=counts_fulldata_%j
#SBATCH --account=bgmp
#SBATCH --partition=bgmp
#SBATCH --output=counts_fulldata_%j.out
#SBATCH --error=counts_fulldata_%j.err
#SBATCH --time=1-23:59:59
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1
#SBATCH --cpus-per-task=8
#SBATCH --mem=64G

conda activate bgmp_py37

dir="/projects/bgmp/shared/groups/2020/neuron_nerds"

/usr/bin/time -v \
$dir/CellRanger/cellranger-4.0.0/bin/cellranger count \
--id=full_count \
--fastqs=$dir/full_data/TrimmedFull \
--sample=L35291_Trimmed \
--transcriptome=$dir/refdata-gex-mm10-2020-A \
--localcores=8 \
--localmem=64

sbatch counts_fulldata.sh


tail -20 counts_fulldata_13541616.out
Outputs:
- Run summary HTML:                         /projects/bgmp/shared/groups/2020/neuron_nerds/chris/full_count/outs/web_summary.html
- Run summary CSV:                          /projects/bgmp/shared/groups/2020/neuron_nerds/chris/full_count/outs/metrics_summary.csv
- BAM:                                      /projects/bgmp/shared/groups/2020/neuron_nerds/chris/full_count/outs/possorted_genome_bam.bam
- BAM index:                                /projects/bgmp/shared/groups/2020/neuron_nerds/chris/full_count/outs/possorted_genome_bam.bam.bai
- Filtered feature-barcode matrices MEX:    /projects/bgmp/shared/groups/2020/neuron_nerds/chris/full_count/outs/filtered_feature_bc_matrix
- Filtered feature-barcode matrices HDF5:   /projects/bgmp/shared/groups/2020/neuron_nerds/chris/full_count/outs/filtered_feature_bc_matrix.h5
- Unfiltered feature-barcode matrices MEX:  /projects/bgmp/shared/groups/2020/neuron_nerds/chris/full_count/outs/raw_feature_bc_matrix
- Unfiltered feature-barcode matrices HDF5: /projects/bgmp/shared/groups/2020/neuron_nerds/chris/full_count/outs/raw_feature_bc_matrix.h5
- Secondary analysis output CSV:            /projects/bgmp/shared/groups/2020/neuron_nerds/chris/full_count/outs/analysis
- Per-molecule read information:            /projects/bgmp/shared/groups/2020/neuron_nerds/chris/full_count/outs/molecule_info.h5
- CRISPR-specific analysis:                 null
- Loupe Browser file:                       /projects/bgmp/shared/groups/2020/neuron_nerds/chris/full_count/outs/cloupe.cloupe
- Feature Reference:                        null
- Target Panel File:                        null

Waiting 6 seconds for UI to do final refresh.
Pipestance completed successfully!

2020-10-31 05:10:08 Shutting down.

Biggest changes were:
increased estimated number of cells: 9,149
increased mean reads per cell: 38,189
increased total genes detected: 23,280

Now going to take the filtered counts into seurat
/projects/bgmp/shared/groups/2020/neuron_nerds/chris/full_count/outs/filtered_feature_bc_matrix

conda activate bgmp_py37
ml rstudio
ml R/4.0.2
rstudio

is the feature violin plot supposed to look bimodal?
look up geom_boxplot
removed dots from violin plot
MT-> mt
upped the number of features from 2500 to 5000 in the filter step

----------------------
|     11/01/2020     |
----------------------

conda activate bgmp_py37
ml rstudio
ml R/4.0.2
rstudio

https://satijalab.org/seurat/v3.2/pbmc3k_tutorial.html 

1. The number of unique genes detected in each cell.
    a. Low-quality cells or empty droplets will often have very few genes
    b. Cell doublets or multiplets may exhibit an aberrantly high gene count
2. Similarly, the total number of molecules detected within a cell (correlates strongly with unique genes)
3. The percentage of reads that map to the mitochondrial genome
    a. Low-quality / dying cells often exhibit extensive mitochondrial contamination
    b. We calculate mitochondrial QC metrics with the PercentageFeatureSet function, which calculates the percentage of counts originating from a set of features
    c. We use the set of all genes starting with MT- as a set of mitochondrial genes

https://kb.10xgenomics.com/hc/en-us/articles/360001086611-Why-do-I-see-a-high-level-of-mitochondrial-gene-expression-

This Technical Note discusses the impact of non-viable cells in single cell suspensions on single cell genomics data quality. 10x Genomics' Single Cell Protocols 
require suspensions of viable, single cells as input. The removal of dead cells and other contaminants from single cell suspensions is critical to obtaining 
high quality data. Depending on the sample type and sample preparation method, the fraction of dead cells in a single cell suspension can vary significantly. 
Dead cells easily lyse, resulting in the release of ambient RNA. This cell-free RNA can contribute to the background noise of the assay and will compromise 
the quality of single cell data. In this Technical Note we compare datasets generated from single cell suspensions containing varying amounts of non-viable 
cells to highlight the importance of removing dead cells from single cell suspensions prior to use with the Single Cell 3’ v2 Protocol.

https://pair-code.github.io/understanding-umap/

The most important parameter is n_neighbors - the number of approximate nearest neighbors used to construct the initial high-dimensional graph. 
It effectively controls how UMAP balances local versus global structure - low values will push UMAP to focus more on local structure by constraining 
the number of neighboring points considered when analyzing the data in high dimensions, while high values will push UMAP towards representing the 
big-picture structure while losing fine detail.

The second parameter we’ll investigate is min_dist, or the minimum distance between points in low-dimensional space. 
This parameter controls how tightly UMAP clumps points together, with low values leading to more tightly packed embeddings. 
Larger values of min_dist will make UMAP pack points together more loosely, focusing instead on the preservation of the broad topological structure.

Questions:
1. How to choose the mitochondrial cutoffs? 
2. How to choose the number of clusters?

----------------------
|     11/03/2020     |
----------------------

Meeting with Annie 

mitchondrial cutoff can be 10, can try 20
look at the marker genes and label clusters
clustering <- need to schedule a meeting with Ron
bioarchive mouse epithelial single cell; marker genes 
sctransform vignette (on the seurat page) <- do not need to do normalize, etc. 
need to check doublet and ambient RNA contamination

----------------------
|     11/04/2020     |
----------------------

filtered vs. raw (Matt and Alyx are playing around with the raw counts)

use dims = 50 as a param in Jackstraw and ScoreJackStraw
-> elbow plot still did not level out

try 100?
100 crashed
trying 80
80 crashed
trying 50

percent.mt: 5, 10, 20
w/ and w/o doubletfinder

ml rstudio
ml R/4.0.2
rstudio

5 done

----------------------
|     11/05/2020     |
----------------------

10 done
20 done

now trying with raw?
mt 5
mt 10 done
mt 20 done

----------------------
|     11/05/2020     |
----------------------

finishing up raw mt 5

need to try doubletfinder

----------------------
|     11/10/2020     |
----------------------

Trying to figure out labeling cells

http://bioconductor.org/packages/release/bioc/html/AnnotationHub.html

if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

BiocManager::install("AnnotationHub")

library(AnnotationHub)

BiocManager::install("ensembldb")
library(ensembldb)

https://hbctraining.github.io/scRNA-seq/lessons/fetching_annotations.html

# Connect to AnnotationHub
ah <- AnnotationHub()

# Access the Ensembl database for organism
ahDb <- query(ah, 
              pattern = c("Homo sapiens", "EnsDb"), 
              ignore.case = TRUE)

# Acquire the latest annotation files
id <- ahDb %>%
        mcols() %>%
        rownames() %>%
        tail(n = 1)

# Download the appropriate Ensembldb database
edb <- ah[[id]]

# Extract gene-level information from database
annotations <- genes(edb, 
                     return.type = "data.frame")

# Select annotations of interest
annotations <- annotations %>%
        dplyr::select(gene_id, gene_name, seq_name, gene_biotype, description)

https://hbctraining.github.io/scRNA-seq/lessons/09_merged_SC_marker_identification.html

gave up on learning about clusters from the descriptions

seeing which clusters have my biomarkers and sorting them by that

could possibly use this:

BuildClusterTree(object = object, 
                 genes.use = object@var.genes, 
                 do.plot = TRUE, 
                 do.reorder = TRUE, 
                 reorder.numeric = TRUE,
                 show.progress = TRUE)

PlotClusterTree

^ if the above works, can use StackedVlnPlit to overlay violin plot

----------------------
|     11/11/2020     |
----------------------

In the end used violin plots and excel to make best guess

SCT is the best, followed by 10, 20, 5.
20 - clustering by mitochondrial genes
5 - not enough information 

https://rpubs.com/DarrenVan/628853
stacked violinplots

----------------------
|     11/13/2020     |
----------------------

https://bioinformatics.stackexchange.com/questions/4297/resolution-parameter-in-seurats-findclusters-function-for-larger-cell-numbers


----------------------
|     11/16/2020     |
----------------------

testing new parameters
see meeting notes

SCTransform after subsetting mt.percent 5-10%
Percent.mt cutoffs:
    2% - Alyx
    2.5% - Alyx
    5% - Matt
    7.5% - Matt
    10% - Chris
    20% - Chris
Look for other cell markers in the literature - Alyx
    Connective tissue 
        fibronectin, fgf? 
        fibroblasts?
    Olfactory sheathing cells?
        S100a5
        S100a6
    Lamina propria
        ATF7
        ACPA2
        FABP7	
Top genes analysis for unknown clusters (UND) - Chris
Cell trajectory analysis - Matt, differences between tools
    Slingshot
    Monocle3

Do not need to do SIMLR. No need for GO/KEGG analysis?
Use soupx to remove ambient RNA?
    Good when analyzing raw counts matrix

----------------------
|     12/02/2020     |
----------------------

It looks like having the mitochondrial contamination cutoff did not help improve the clustering
Looking at the annotated top 10 genes, it looks like we might have immune cells () and sus-similar cells (krt18, cyp2g1, cyp1a5). Might be able to use the s100a5 markers

Monocle3 is easier to use than slingshot and the satjia lab already has a vignette on this.

https://github.com/satijalab/seurat/issues/1658
https://satijalab.org/signac/articles/monocle.html

----------------------
|     12/04/2020     |
----------------------

How is RNA Velocity different from Cell Trajectory? Velocity includes time/rate

RNA Velocity
    https://velocyto.org/velocyto.py/tutorial/cli.html#run10x-run-on-10x-chromium-samples

Good tools for GO/KEGG: 
    Panther (newer), 
    David (for GO terms; older, easier to use, smaller datasets needed within the cell cluster)

Finding unknown cluster ID’s:
    Extract the cluster and rerun through the pipeline
    Gene enrichment comparisons: pct1/pct2 - look for big numbers?
    Get the top all genes for that cluster:
    PCT1 : the percent of cells in that cluster that express that marker
    Check for pct >85%?
    PCT2: percentage of all other cells combined that express that marker
    Take that cluster’s ratio as “cluster gene IDs”
    Could multiply this ratio by the avg_logFC
    Average Expression Table
    Gene ID, Cluster ID
    Has every gene that is expressed in any cluster, normalized so that sum of each column (cluster 0) adds up to 10000
    Reads per 10000 instead of reads per million to normalize expression values
    Good for getting a “first glance”
    Max(per column) finds the most expressed gene in each cluster
    Doesn’t compare against other clusters, just within cluster
    Create a percentage for each gene based on average expression within cluster

    https://rdrr.io/github/satijalab/seurat/man/AverageExpression.html

Exporting dataframes from R as an excel table
    https://www.statmethods.net/input/exportingdata.html

    library(xlsx)
    write.xlsx(mydata, "c:/mydata.xlsx")

----------------------
|     12/06/2020     |
----------------------

Dr. Yu is concerned about the prevalence of OMP in the cell clusters. Suggests using SoupX

SoupX - https://rdrr.io/cran/SoupX/f/vignettes/pbmcTutorial.Rmd

Figured out how to use VLOOKUP in excel:
http://biocc.hrbmu.edu.cn/CellMarker/

found markers to differentiate UND clusters:

Potential Cell: Type	Marker 1	Marker 2	Marker 3	Marker 4	Marker 5	
Late activated neural stem cell:	Top2a	Neurod1				
chandelier cell/osteogenic cell:	Spp1	Ibsp	Col1a1	Bglap	Col1a2	
Type II spiral ganglion neuron:	Cd74	H2-Aa	H2-Ab1			
Mural Cell:	Rgs5	Acta2	Myl9			
Endothelial cell:	Ctla2a	Aplnr	Flt1	Clec14a		
Adipose tissue:	Sfrp2	Col3a1	Dcn	Lum	Col1a1	Col1a2	
Neural stem cell/Olfactory ensheathing glia:	Fabp7	Plp1	Apoe			
lymphocyte (Lacrimal gland):	Cxcr6	Cd3g	Trbc2	Cd3d	Ptprcap	

----------------------
|     12/23/2020     |
----------------------

Objective: RNA Velocity

http://velocyto.org/
https://jef.works/blog/2020/01/14/rna_velocity_analysis_tutorial_tips/

download openmp and boost packages in my conda environment in the ubuntu terminal
conda install -c conda-forge openmpi
conda install -c conda-forge boost

in R terminal
install.packages("devtools")

restart R
library(devtools)
install_github("velocyto-team/velocyto.R")

Error: Failed to install 'velocyto.R' from GitHub:
    (converted from warning) package 'pcaMethods' is not available (for R version 4.0.2)

BiocManager::install("pcaMethods")
^ this updated seurat and sctransform

retried install_github(velocyto)

Error: Failed to install 'velocyto.R' from GitHub:
    (converted from warning) installation of package 'hdf5r' had non-zero exit status

retried install_github(velocyto)

These packages have more recent versions available.
It is recommended to update all of them.
Which would you like to update? 

1: All
2: CRAN packages only
3: None
4: igraph (1.2.5 -> 1.2.6) [CRAN]

install.packages("igraph")

Error: package or namespace load failed for 'igraph' in dyn.load(file, DLLpath = DLLpath, ...)
    unable to load shared object '/gfs/home/cchua/R/x86_64-pc-linux/4.0/...
    libicuil8n.so.58: cannot open shared object file: No such file or directory

might need a new compiler because R version is too recent
re: https://github.com/igraph/rigraph/issues/213


01/04/2021

https://github.com/velocyto-team/velocyto.R/pull/43

01/05/2021

meeting with Jason and Pete to resolve the environment

alyx's error when installing using bioconductor::rhd5f
ERROR: unable to lcoate HDF5 compilation helper scripts 'h5cc' or 'h5pcc'

ml rstudio
ml R/4.0.2

conda install -c conda-forge openmpi <- already installed
conda install -c conda-forge boost <- already installed
conda install -c bioconda bioconductor-rhdf5 <--- new

library(devtools)
install_github("velocyto-team/velocyto.R")

Unable to locate HDF5 compilation helper scripts 'h5cc' pr 'h5pcc'.
Please specify --with-hdf5=<LOCATION> as the full path to h5cc or h5pcc

sudo apt-get install libhdf5-dev

Pete's suggestion
if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
BiocManager::install("rhdf5")

"The downloaded source packages are in 
    '/tmp/Rtmp55YI7F/downloaded-packages'
Installation path not writeable, unable to update packages: ade4, backports, bibtex, bit64, broom, callr, car, cli, clipr,
    clusterGeneration, coda, codetools, colorspace, colourpicker, config, conquer, covr, cowplot, cppll, data.table, dbplyr,
    ...

same error 

# no cross talk between ml and env?
new terminal
which R
/bin/R

which conda
/projects/bgmp/cchua/miniconda3/bin/conda

conda activate bgmp_pmy37
which R
/projects/bgmp/cchua/miniconda3/envs/bgmp_py37/bin/R

which conda

R packages live in in packages
conda packages live in conda

Create velocyto specific environment
conda create --name SomeName
conda config --add channels conda-forge
conda search r-base
#^ will show you all the versions of R you can choose
conda install r-base=x.y.z

created bgmp_R

need to load all dependecies first in conda before install packages in R <-- THIS IS KEY*****
conda install r-base=4.0.2
conda install -c rstudio <- do not do this

conda install -c bioconda r-velocyto.r

conda list | grep !velo

Pete suggestion:
point to conda R version path in rstudio

library(dplyr)
library(Seurat)
library(patchwork)
library(ggplot2)

## In conclusion:

create new environment
download R and velocyto
module load rstudio then R

conda activate bgmp_R
ml rstudio
ml R/4.0.2
rstudio
library(velocyto.R)

system("type R")
file.path(R.home("bin"), "R")

R is /packages/R/4.0.2_gcc7/bin/R
[1] "projects/bgmp/cchua/miniconda3/envs/bgmp_R/lib/R/bin/R"

##################################################################

# Jason's Notes:

# Summary:
# * Problems installing r-velocyto.r.
# * Able to install r-velocyto.r via conda.
# * Also ablve to install rstudio via conda.
#     - Why do this? Possible problems with different versions of R needed
#         by different packages such as rstduio and some of the other ones.
#     - Maybe try installing via source????
# * rstudio installed via conda requires / ends up with R version 3.6.1.
#     - Note some packages may be unahppy with 3.6.1, we don't know yet though?
# * Installed other packages from within R (install.packages())
# * But MUDAN is being difficult. No o
#
# * Pete's suggestion of rstduio installed via source might be very promising.
# * Another thing to do is look at MUDAN's R version requirements, if any?
#     - See if other peopel have been able to install MUDAN?
#     - FIRST! Install MUDAN in it's own clean envionrment under different
#         versions of R, just to see if you can do it.
#     - It's actually a MUDAN requirement (sva) that is failing install. Here
#         is the error:
#                 Execution halted
#                 ERROR: lazy loading failed for package ‘sva’
#                 * removing ‘/gpfs/projects/postlethwait/sydes/miniconda3/envs/velocityo-play5/lib/R/library/sva’
#                 Error: Failed to install 'MUDAN' from GitHub:
#                   (converted from warning) installation of package ‘sva’ had non-zero exit status
#
#
# * DO you really *need* MUDAN?  Can you possible do some sort of r-object export to
#     a file, then load it in under a different version of R, or SOMETHING like that?


####################################################
####################################################
####################################################

# On talapas OnDemand:
# conda create -n velocityo-play5
# conda activate velocityo-play5
# conda install r-velocyto.r rstudio r-devtools
# rstudio

####################################################
####################################################
####################################################

# The R script:

# One time only:
install.packages('irlba')
install.packages('Rtsne')
install.packages('RANN')
install.packages('igraph')

# Load up the libraries
require(devtools)
library(irlba)
library(Rtsne)
library(RANN)
library(igraph)

library(velocyto.R)

# Everything up to here seems to work??!!
# But MUDAN install fails.  Sad.

devtools::install_github('JEFworks/MUDAN')
library(MUDAN)

http://htmlpreview.github.io/?https://github.com/satijalab/seurat-wrappers/blob/master/docs/scvelo.html

https://htmlpreview.github.io/?https://github.com/satijalab/seurat.wrappers/blob/master/docs/velocity.html

subcluster then redo seurat for just iOSNs and mOSNs?

in R terminal
install.packages("devtools")

restart R
library(devtools)
install_github("velocyto-team/velocyto.R")
remotes::install_github('satijalab/seurat-wrappers')

nadia_30dpf_merged_subsetClusters <- SubsetData(object = nadia_30dpf_merged, ident.remove =c(34), do.clean = TRUE, subet.raw = TRUE)


# Matt
sed 's/\t/,/g' file.tsv > file.csv
                                Create new conda environment: velocytoR3
                                conda config --add channels bioconda
                                conda config --add channels conda-forge
                                conda install -c conda-forge r-devtools
                                conda install r-base=4.0.2
                                conda install -c bioconda r-velocyto.r
                                conda install r-biomartr
                                ml R/4.0.2
                                rstudio



#!/bin/bash
#SBATCH --partition=bgmp        ### Partition (like a queue in PBS)
#SBATCH --account=bgmp          ### Account used for job submission

/usr/bin/time -v zcat features.tsv.gz | sed 's/\t/,/g' > features.csv

### FINAL

conda remove --name bgmp_R --all
conda create --name bgmp_R
conda activate bgmp_R
conda config --add channels bioconda
conda config --add channels conda-forge
conda install -c conda-forge r-devtools
conda install r-base=4.0.2
conda install -c bioconda r-velocyto.r
conda install r-biomartr <- leave off
ml rstudio
ml R/4.0.2
rstudio
install.packages("Seurat")
library(devtools)
install_github('satijalab/seurat-wrappers')

installing seurat after devtools removes devtools

can use install_github without devtools by using remotes::install_github

after installing seuratwrapper cannot load seurat or seuratwrapper libraries; missing ZLIB_1.2.9

01/06/2021